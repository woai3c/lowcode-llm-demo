{
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Python: main.py",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/ptuning/main.py",
            "args": [
                "--do_train",
                "--train_file", "${workspaceFolder}/ptuning/train-data/train.json",
                "--validation_file", "${workspaceFolder}/ptuning/train-data/dev.json",
                "--prompt_column", "content",
                "--response_column", "summary",
                "--overwrite_cache",
                "--model_name_or_path", "D:\\res\\lowcode-llm-demo",
                "--output_dir", "output/adgen-chatglm-6b-pt-128-2e-2",
                "--overwrite_output_dir",
                "--max_source_length", "64",
                "--max_target_length", "64",
                "--per_device_train_batch_size", "1",
                "--per_device_eval_batch_size", "1",
                "--gradient_accumulation_steps", "16",
                "--predict_with_generate",
                "--max_steps", "3000",
                "--logging_steps", "10",
                "--save_steps", "1000",
                "--learning_rate", "2e-2",
                "--pre_seq_len", "128",
                "--quantization_bit", "4"
            ]
        }
    ]
}